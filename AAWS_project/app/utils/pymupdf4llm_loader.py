import os
import re
import base64
import time
from typing import Iterator, Optional, Literal, Union, List
from concurrent.futures import ThreadPoolExecutor

import pymupdf4llm
from langchain_core.document_loaders import BaseLoader
from langchain_core.documents import Document
from langchain_core.messages import HumanMessage
from langchain_core.language_models import BaseChatModel


'''
1. í…ìŠ¤íŠ¸ë§Œ í•„ìš”í•  ë•Œ (ê°€ìž¥ ë¹ ë¦„)

    loader = PyMuPDF4LLMLoader("doc.pdf", extract_images=False)
    docs = loader.load()

2. í…ìŠ¤íŠ¸ ì¶”ì¶œê³¼ í•¨ê»˜ ì´ë¯¸ì§€ ì €ìž¥
    #ì´ë¯¸ì§€ê°€ ./extracted_images í´ë”ì— pngë¡œ ì €ìž¥ë©ë‹ˆë‹¤.
    #ë§ˆí¬ë‹¤ìš´ í…ìŠ¤íŠ¸ì—ëŠ” ![ì´ë¯¸ì§€](./extracted_images/img1.png) ë§í¬ê°€ ë‚¨ìŠµë‹ˆë‹¤.
    #LLM ë¹„ìš©ì´ ë“¤ì§€ ì•ŠìŠµë‹ˆë‹¤.

    loader = PyMuPDF4LLMLoader(
        "doc.pdf", 
        extract_images=True, 
        model=None  # ëª¨ë¸ì„ ì•ˆ ë„£ìœ¼ë©´ ì¶”ì¶œë§Œ í•¨
    )
    docs = loader.load()

3. ì´ë¯¸ì§€ ì €ìž¥ + AI ë¶„ì„ê¹Œì§€ : VLMì´ ë‚´ìš©ì„ ë³´ê³  ì´ë¯¸ì§€ ìœ„ì¹˜ì— ëŒ€ì²´ í…ìŠ¤íŠ¸ë¡œ ì¶”ê°€
    gemini = ChatGoogleGenerativeAI(model="gemini-2.0-flash", temperature=0) # Langchain ChatModel
    loader = PyMuPDF4LLMLoader(
        "doc.pdf", 
        extract_images=True, 
        model=gemini  # ëª¨ë¸ì„ ë„£ìœ¼ë©´ ë¶„ì„ê¹Œì§€ í•¨
    )
    docs = loader.load()
'''

class PyMuPDF4LLMLoader(BaseLoader):
    def __init__(
        self,
        file_path: str,
        mode: Literal["page", "single"] = "page",
        extract_images: bool = False,
        model: Optional[BaseChatModel] = None,
        image_output_dir: str = "extracted_images",
        max_workers: int = 5  # ë³‘ë ¬ ì›Œì»¤ ìˆ˜
    ):
        self.file_path = file_path
        self.mode = mode
        self.extract_images = extract_images
        self.model = model
        self.image_output_dir = image_output_dir
        self.max_workers = max_workers

    def lazy_load(self) -> Iterator[Document]:
        if self.extract_images:
            os.makedirs(self.image_output_dir, exist_ok=True)
            
            # action ë³€ìˆ˜ ì„¤ì • (ë³‘ë ¬ ì›Œì»¤ ìˆ˜ ì •ë³´ í¬í•¨)
            base_action = "Analysis" if self.model else "Extraction Only"
            action = f"{base_action} (Parallel x{self.max_workers})"
            
            # âœ… ìš”ì²­í•˜ì‹  í¬ë§· ì ìš©
            print(f"ðŸ“‚ [Loader] PDF ë¡œë“œ: {self.file_path} (Images: {action}, Mode: {self.mode})")
        
        # 1. CPU íŒŒì‹± (ìˆœì°¨)
        raw_output = pymupdf4llm.to_markdown(
            doc=self.file_path,
            page_chunks=(self.mode == "page"),
            write_images=self.extract_images,
            image_path=self.image_output_dir if self.extract_images else None,
            image_format="png",
            dpi=300,
            force_text=True
        )

        # 2. ê²°ê³¼ ì²˜ë¦¬ (ë³‘ë ¬)
        if self.mode == "page":
            yield from self._process_page_mode_parallel(raw_output)
        else:
            yield from self._process_single_mode(raw_output)

    def _process_page_mode_parallel(self, raw_pages: list) -> Iterator[Document]:
        total_pages = len(raw_pages)
        print(f"   ðŸš€ {total_pages}ê°œ íŽ˜ì´ì§€ ë³‘ë ¬ ë¶„ì„ ì‹œìž‘...")
        
        futures = []
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # ìž‘ì—… ì œì¶œ
            for i, page_data in enumerate(raw_pages):
                future = executor.submit(self._process_single_page_task, page_data, i)
                futures.append(future)
            
            # ê²°ê³¼ ìˆ˜ì§‘ (ìˆœì„œ ë³´ìž¥)
            for i, future in enumerate(futures):
                try:
                    doc = future.result() # ì—¬ê¸°ì„œ ì™„ë£Œë  ë•Œê¹Œì§€ ëŒ€ê¸°
                    
                    # ì§„í–‰ ìƒí™© ì¶œë ¥ (tqdm ëŒ€ì²´)
                    # ì˜ˆ: [Loader] Progress: 3/10 (30.0%) ì™„ë£Œ
                    progress = i + 1
                    percent = (progress / total_pages) * 100
                    print(f"   â³ [Progress] {progress}/{total_pages} ({percent:.1f}%) - Page {doc.metadata.get('page')} ì™„ë£Œ")
                    
                    yield doc
                except Exception as e:
                    print(f"   âŒ Error processing page {i+1}: {e}")

    def _process_single_page_task(self, page_data: dict, index: int) -> Document:
        text = page_data["text"]
        meta = page_data["metadata"].copy()
        
        if 'file_path' in meta: meta['source'] = meta['file_path']
        
        # ì´ë¯¸ì§€ ë¶„ì„ (VLM í˜¸ì¶œ)
        if self.extract_images and self.model:
            text = self._replace_images_with_captions(text, page_num=meta.get('page'))
        
        if self.extract_images:
            meta['has_images'] = bool(page_data.get('images'))
        else:
            meta['has_images'] = False

        meta.pop('images', None)
        meta.pop('tables', None)
        
        return Document(page_content=text, metadata=meta)

    def _replace_images_with_captions(self, text: str, page_num: Union[int, str]) -> str:
        image_links = re.findall(r'!\[(.*?)\]\((.*?)\)', text)
        if not image_links: return text
        
        for alt, path in image_links:
            if os.path.exists(path):
                # VLM í˜¸ì¶œ
                caption = self._analyze_image(path)
                original = f"![{alt}]({path})"
                replacement = f"{original}\n\n> **[ì´ë¯¸ì§€ ì„¤ëª…]** {caption}\n"
                text = text.replace(original, replacement)
        return text

    def _analyze_image(self, image_path: str) -> str:
        try:
            with open(image_path, "rb") as f:
                img_data = base64.b64encode(f.read()).decode("utf-8")
            
            msg = HumanMessage(content=[
                {"type": "text", "text": "Describe this image in detail for RAG context retrieval."},
                {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{img_data}"}}
            ])
            return self.model.invoke([msg]).content.strip()
        except Exception as e:
            return f"(Error: {e})"