import json
import pandas as pd
from datasets import Dataset
from langchain_openai import ChatOpenAI, OpenAIEmbeddings

# RAGAS Imports
from ragas import evaluate as ragas_evaluate
from ragas.metrics import Faithfulness, AnswerRelevancy, ContextPrecision, ContextRecall

# JSON Parsing Helper (RAGAS ì•ˆì •ì„± í™•ë³´ìš©)
class JSONCleanLLM(ChatOpenAI):
    def _clean(self, text):
        if "```json" in text: return text.replace("```json", "").replace("```", "").strip()
        if "```" in text: return text.replace("```", "").strip()
        return text

    async def agenerate(self, messages, stop=None, **kwargs):
        result = await super().agenerate(messages, stop=stop, **kwargs)
        for gens in result.generations:
            for gen in gens:
                gen.text = self._clean(gen.text)
        return result

async def run_ragas_evaluation(
    agent_executor, 
    dataset_path: str, 
    output_file: str = "ragas_results.csv",
    project_name: str = "RAG_Evaluation"
):
    """
    CSV ë°ì´í„°ì…‹ì„ ë¡œë“œí•˜ì—¬ Agentë¥¼ ì‹¤í–‰í•˜ê³  RAGASë¡œ í‰ê°€í•©ë‹ˆë‹¤.
    
    Args:
        agent_executor: í‰ê°€í•  LangGraph Agent Executor
        dataset_path: Golden Dataset CSV íŒŒì¼ ê²½ë¡œ
        output_file: í‰ê°€ ê²°ê³¼ë¥¼ ì €ì¥í•  CSV ê²½ë¡œ
        project_name: (Optional) ë¡œê¹…ìš© í”„ë¡œì íŠ¸ ì´ë¦„
    """
    
    print(f"ğŸ“Š í‰ê°€ ì‹œì‘: {dataset_path} -> Agent")
    
    # 1. ë°ì´í„°ì…‹ ë¡œë“œ
    try:
        df = pd.read_csv(dataset_path)
    except Exception as e:
        print(f"âŒ ë°ì´í„°ì…‹ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None
        
    questions = df["question"].tolist()
    # RAGAS ìµœì‹  ë²„ì „ SingleTurnSample í˜¸í™˜ì„± ìˆ˜ì •: 
    # reference(ground_truth)ëŠ” List[str] ëŒ€ì‹  strë¡œ ì „ë‹¬ (ë‹¨ì¼ ì •ë‹µì¸ ê²½ìš°)
    ground_truths = df["answer"].tolist() 
    # ground_truth_contexts = [[ctx] for ctx in df["ground_truth_context"].tolist()] # Optional
    
    answers = []
    contexts_list = []
    
    # 2. Agent ì‹¤í–‰ ë° ë°ì´í„° ìˆ˜ì§‘
    print(f"ğŸš€ ì´ {len(questions)}ê°œ ì§ˆë¬¸ì— ëŒ€í•´ Agent ì‹¤í–‰ ì¤‘...")
    
    for i, q in enumerate(questions):
        print(f"  - [{i+1}/{len(questions)}] ì§ˆë¬¸: {q[:30]}...")
        try:
            # Agent ì‹¤í–‰ (Thread IDë¥¼ ë¶„ë¦¬í•˜ì—¬ ë…ë¦½ì„± ë³´ì¥)
            result = await agent_executor.ainvoke(
                {"messages": [("user", q)]},
                config={"configurable": {"thread_id": f"eval_{project_name}_{i}"}}
            )
            
            # A. ë‹µë³€ ì¶”ì¶œ
            last_msg = result["messages"][-1]
            answers.append(last_msg.content)
            
            # B. Context ì¶”ì¶œ (ToolMessage parsing)
            # ìš°ë¦¬ ì‹œìŠ¤í…œì˜ Toolì€ JSON stringì„ ë°˜í™˜í•˜ë¯€ë¡œ íŒŒì‹± í•„ìš”
            retrieved_ctx = []
            for msg in result["messages"]:
                if msg.type == "tool":
                    try:
                        # tool outputì´ json stringì¸ ê²½ìš°
                        content_dict = json.loads(msg.content)
                        if "context" in content_dict:
                            # contextê°€ ê¸´ ë¬¸ìì—´ í•˜ë‚˜ë¡œ ë˜ì–´ìˆìœ¼ë¯€ë¡œ ë¦¬ìŠ¤íŠ¸ì— ë‹´ìŒ
                            retrieved_ctx.append(content_dict["context"])
                    except:
                        # jsonì´ ì•„ë‹ˆê±°ë‚˜ ì‹¤íŒ¨í•˜ë©´ raw content ì‚¬ìš© (fallback)
                        retrieved_ctx.append(str(msg.content))
            
            # ê²€ìƒ‰ëœê²Œ ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´ ì²˜ë¦¬
            contexts_list.append(retrieved_ctx if retrieved_ctx else [""])
            
        except Exception as e:
            print(f"    âš ï¸ Agent ì‹¤í–‰ ì—ëŸ¬: {e}")
            answers.append("Error occurred")
            contexts_list.append([""])

    # 3. RAGAS Dataset êµ¬ì„±
    data_dict = {
        "question": questions,
        "answer": answers,
        "contexts": contexts_list,
        "ground_truth": ground_truths
    }
    ragas_dataset = Dataset.from_dict(data_dict)
    
    # 4. í‰ê°€ ëª¨ë¸ ì„¤ì •
    judge_llm = JSONCleanLLM(model="gpt-4o", temperature=0)
    creative_llm = JSONCleanLLM(model="gpt-4o", temperature=0.7)
    embeddings = OpenAIEmbeddings(model="text-embedding-3-large")
    
    metrics = [
        Faithfulness(llm=judge_llm),
        ContextPrecision(llm=judge_llm),
        ContextRecall(llm=judge_llm),
        AnswerRelevancy(llm=creative_llm, embeddings=embeddings)
    ]
    
    # 5. RAGAS ì‹¤í–‰
    print("âš–ï¸ RAGAS Metrics ê³„ì‚° ì¤‘...")
    results = ragas_evaluate(
        ragas_dataset,
        metrics=metrics,
        llm=judge_llm,
        embeddings=embeddings
    )
    
    # 6. ê²°ê³¼ ì €ì¥
    df_result = results.to_pandas()
    df_result.to_csv(output_file, index=False, encoding='utf-8-sig')
    print(f"âœ… í‰ê°€ ì™„ë£Œ! ê²°ê³¼ ì €ì¥ë¨: {output_file}")
    
    return results
