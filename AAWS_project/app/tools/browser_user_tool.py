from browser_use import Browser, Agent, ChatGoogle
from langchain_core.tools import tool
import os

# DISPLAY í™˜ê²½ë³€ìˆ˜ í™•ì¸
print(f"âœ… DISPLAY: {os.environ.get('DISPLAY', 'NOT SET')}")

try:
    # ğŸ’¡ í•µì‹¬: ì„¸ì…˜ì„ ìœ ì§€í•˜ëŠ” ê³µìœ  ë¸Œë¼ìš°ì € ì¸ìŠ¤í„´ìŠ¤ë¥¼ í•˜ë‚˜ë§Œ ìƒì„±í•©ë‹ˆë‹¤.
    print("ğŸš€ ë¸Œë¼ìš°ì € ì‹œì‘ ì¤‘...")
    shared_browser = Browser(
        headless=False,
        disable_security=True,
        window_size={'width': 1280, 'height': 720},
        keep_alive=True  # ë„êµ¬ í˜¸ì¶œì´ ëë‚˜ë„ ë¸Œë¼ìš°ì €ê°€ ì¢…ë£Œë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
    )
    print("âœ… ë¸Œë¼ìš°ì € ìƒì„± ì„±ê³µ!")
except Exception as e:
    print(f"âŒ ë¸Œë¼ìš°ì € ìƒì„± ì‹¤íŒ¨: {e}")
    import traceback
    traceback.print_exc()
    raise

@tool
async def browse_web_keep_alive(instruction: str) -> str:
    """
    ê³µìœ ëœ ë¸Œë¼ìš°ì € ì„¸ì…˜ì„ ì‚¬ìš©í•˜ì—¬ ì›¹ íƒìƒ‰ì„ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    ì—¬ëŸ¬ í„´ì˜ ë„êµ¬ í˜¸ì¶œì—ì„œ ë¸Œë¼ìš°ì € ìƒíƒœ(í˜„ì¬ í˜ì´ì§€, ë¡œê·¸ì¸ ìƒíƒœ ë“±)ë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.
    
    Args:
        instruction: ë¸Œë¼ìš°ì €ê°€ ìˆ˜í–‰í•´ì•¼ í•  êµ¬ì²´ì ì¸ í–‰ë™ ì§€ì‹œë¬¸ (ì˜ˆ: 'í˜„ì¬ í˜ì´ì§€ì—ì„œ ë‘ ë²ˆì§¸ ë§í¬ í´ë¦­í•´')
    """
    print(f"\nğŸŒ [Browser Tool - Keep Alive] í–‰ë™ ê°œì‹œ: {instruction}")
    
    bu_llm = ChatGoogle(model="gemini-flash-latest")
    #bu_llm = ChatOpenAI(model="gpt-5-mini-2025-08-07")
    
    # ê³µìœ  ë¸Œë¼ìš°ì €ë¥¼ ì „ë‹¬í•´ì„œ ì„¸ì…˜ì„ ìœ ì§€í•©ë‹ˆë‹¤.
    agent = Agent(task=instruction, llm=bu_llm, browser=shared_browser)
    history = await agent.run(max_steps=10)
    
    result_text = history.final_result()
    if not result_text:
        return "ë¸Œë¼ìš°ì € ì¡°ì‘ì„ ì‹œë„í–ˆìœ¼ë‚˜ ëª…í™•í•œ ê²°ê³¼ë¥¼ ì–»ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ëª…ë ¹ìœ¼ë¡œ ì¬ì‹œë„í•´ë³´ì„¸ìš”."
    
    # í˜„ì¬ í˜ì´ì§€ URL ì •ë³´ ì¶”ê°€ (ë§¥ë½ ìœ ì§€ìš©)
    last_url = None
    try:
        if hasattr(history, "urls"):
            urls_list = history.urls() or []
            if urls_list:
                last_url = urls_list[-1]
    except Exception:
        last_url = None
    
    if not last_url:
        try:
            all_results = getattr(history, "all_results", None) or getattr(history, "results", None) or []
            for item in reversed(all_results):
                text_candidates = []
                if hasattr(item, "long_term_memory") and item.long_term_memory:
                    text_candidates.append(item.long_term_memory)
                if hasattr(item, "extracted_content") and item.extracted_content:
                    text_candidates.append(item.extracted_content)
                if hasattr(item, "extracted_content") and isinstance(item.extracted_content, list):
                    text_candidates.extend(item.extracted_content)
                for t in text_candidates:
                    if isinstance(t, str) and ("http://" in t or "https://" in t):
                        import re
                        m = re.search(r"https?://[^\s,'\)\]]+", t)
                        if m:
                            last_url = m.group(0)
                            break
                if last_url:
                    break
        except Exception:
            last_url = None

    url_info = f"í˜„ì¬ ìœ„ì¹˜: {last_url}" if last_url else "í˜„ì¬ ìœ„ì¹˜: (URL í™•ì¸ ë¶ˆê°€)"
    
    return f"{url_info}\nê²°ê³¼: {result_text}"
